{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from imutils import paths\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = os.path.normpath(os.path.join(os.path.dirname(os.path.realpath('__file__'))))\n",
    "SOURCE_DIR = os.path.abspath('/data/aumkar/train')\n",
    "TARGET_DIR = os.path.abspath('/data/aumkar/validation')\n",
    "DATA_LOAD_DIR = os.path.abspath('/data/aumkar/data_load')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_path = list(paths.list_images(SOURCE_DIR))\n",
    "target_path = list(paths.list_images(TARGET_DIR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_unique = np.load(os.path.join(DATA_LOAD_DIR, 'labels.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = linear_model.SGDClassifier(max_iter = 100, tol = 1e-3, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lst2arr_reshape(lst, data):\n",
    "    \n",
    "    arr = np.asarray(lst)\n",
    "    \n",
    "    if data == 'data':\n",
    "        return arr.reshape((arr.shape[0] * arr.shape[1], arr.shape[2]))\n",
    "    elif data == 'label':\n",
    "        return arr.reshape((arr.shape[0] * arr.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_gen(start, end, size): \n",
    "    num = [] \n",
    "  \n",
    "    for i in range(size): \n",
    "        num.append(random.randint(start, end)) \n",
    "  \n",
    "    return num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_data_batches(size, pred, lab):\n",
    "    \n",
    "    '''sampid = np.arange(len(target_path))\n",
    "    np.random.shuffle(sampid)'''\n",
    "    \n",
    "    ids = num_gen(0, 865, size)\n",
    "    \n",
    "    x_t = []\n",
    "    y_t = []\n",
    "    \n",
    "    for i in ids:\n",
    "        \n",
    "        data_target = np.load(os.path.join(DATA_LOAD_DIR, 'inception', 'feat_incept_target_%s.npz' % i))\n",
    "        x_t.append(data_target['a'])\n",
    "        \n",
    "        if pred == 'first':\n",
    "                       \n",
    "            pseudo_label = np.load(os.path.join(DATA_LOAD_DIR, 'inception_predictions', 'incept_pred_%s.npz' % i))\n",
    "            y_t.append(pseudo_label['a'])\n",
    "            \n",
    "        elif pred == 'later':\n",
    "            \n",
    "            if i != 865 and i != 0:\n",
    "                y_t.append(lab[(i * 64) : (i * 64) + 64]) #debug (i or (((i - 1) * 64) + 1))\n",
    "            elif i == 0:\n",
    "                y_t.append(lab[:64])\n",
    "            elif i == 865:\n",
    "                y_t.append(lab[-64:])\n",
    "        \n",
    "    if pred == 'first':\n",
    "        return lst2arr_reshape(x_t, 'data'), lst2arr_reshape(y_t, 'label')\n",
    "    elif pred == 'later':\n",
    "        return lst2arr_reshape(x_t, 'data'), np.asarray(y_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictions():\n",
    "    \n",
    "    pred = []\n",
    "    \n",
    "    for i in range(866):\n",
    "        \n",
    "        target_data = np.load(os.path.join(DATA_LOAD_DIR, 'inception', 'feat_incept_target_%s.npz' % i))\n",
    "        target_data_ = target_data['a'].reshape((target_data['a'].shape[0] * target_data['a'].shape[1], target_data['a'].shape[2]))\n",
    "        pred.append(clf.predict(target_data_))\n",
    "        \n",
    "    return np.asarray(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_sslda(sourcex, sourcey, targetx, targety, M):\n",
    "\n",
    "    for i in range(1, M):\n",
    "        \n",
    "        print('Iteration: ', i)\n",
    "         \n",
    "        n = (i / float(M)) * len(target_path)\n",
    "        \n",
    "        if i == 1:\n",
    "            target_sample, target_label = target_data_batches(int(n), 'first', None)\n",
    "        else:\n",
    "            target_sample, target_label = target_data_batches(int(n), 'later', fin_pred)\n",
    "        \n",
    "        for i in range(2382):\n",
    "            \n",
    "            data = np.load(os.path.join(DATA_LOAD_DIR, 'inception', 'feat_incept_%s.npz' % i))\n",
    "            label = np.load(os.path.join(DATA_LOAD_DIR, 'inception', 'feat_incept_label_%s.npz' % i))\n",
    "            \n",
    "            sourcex = data['a'].reshape((data['a'].shape[0] * data['a'].shape[1], data['a'].shape[2]))\n",
    "            sourcey = label['a'].reshape((label['a'].shape[0] * label['a'].shape[1]))\n",
    "                  \n",
    "            concat_sample = np.append(sourcex, target_sample, axis = 0)\n",
    "            concat_label = np.append(sourcey, target_label, axis = 0)\n",
    "            \n",
    "            if i == 0:\n",
    "                clf.partial_fit(concat_sample, concat_label, classes = labels_unique)\n",
    "            else:\n",
    "                clf.partial_fit(concat_sample, concat_label)\n",
    "\n",
    "        print('Predicting for iteration: ', i)\n",
    "            \n",
    "        fin_pred = predictions()\n",
    "        \n",
    "    return fin_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sslda_pred = single_sslda(xsource, ysource, xtarget, ytarget, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['aeroplane', 'bicycle', 'bus', 'car', 'horse', 'knife', 'motorcycle', 'person', 'plant', 'skateboard', \n",
    "          'train', 'truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(ytarget, sslda_pred, target_names = classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (daenv)",
   "language": "python",
   "name": "daenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
