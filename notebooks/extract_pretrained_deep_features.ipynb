{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import csv\n",
    "import os\n",
    "import h5py\n",
    "import itertools\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.layers import *\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.mobilenet import MobileNet\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.applications.xception import Xception\n",
    "from keras.applications.densenet import DenseNet121\n",
    "from keras import backend as k\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = os.path.normpath(os.path.join(os.path.dirname(os.path.realpath('__file__'))))\n",
    "SOURCE_DIR = os.path.abspath('/data/aumkar/train')\n",
    "TARGET_DIR = os.path.abspath('/data/aumkar/validation')\n",
    "DATA_LOAD_DIR = os.path.abspath('/data/aumkar/data_load')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width, img_height = 216, 384\n",
    "batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_gen = ImageDataGenerator(rescale=1. / 255, zoom_range=0.2, horizontal_flip = True, vertical_flip = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 152397 images belonging to 13 classes.\n"
     ]
    }
   ],
   "source": [
    "source_generator = source_gen.flow_from_directory(SOURCE_DIR, target_size=(img_width, img_height), \n",
    "                                                batch_size=batch_size, class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_gen = ImageDataGenerator(rescale=1. / 255, zoom_range=0.2, horizontal_flip = True, vertical_flip = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 55388 images belonging to 13 classes.\n"
     ]
    }
   ],
   "source": [
    "target_generator = target_gen.flow_from_directory(TARGET_DIR, target_size=(img_width, img_height), \n",
    "                                                batch_size=batch_size, class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_source = source_generator.classes\n",
    "y_target = target_generator.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = Input(shape=(img_width, img_height, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_create(transfer_model):\n",
    "    if transfer_model == 'InceptionV3':\n",
    "        with tf.device('/gpu:1'):\n",
    "            model_ = InceptionV3(input_tensor = input_, weights = 'imagenet', include_top = False)\n",
    "        return Model(inputs = model_.input, outputs = model_.output)\n",
    "    elif transfer_model == 'VGG16':\n",
    "        with tf.device('/gpu:1'):\n",
    "            model_ = VGG16(input_tensor = input_, weights = 'imagenet', include_top = False)\n",
    "        return Model(inputs = model_.input, outputs = model_.output)\n",
    "    elif transfer_model == 'VGG19':\n",
    "        with tf.device('/gpu:1'):\n",
    "            model_ = VGG19(input_tensor = input_, weights = 'imagenet', include_top = False)\n",
    "        return Model(inputs = model_.input, outputs = model_.output)\n",
    "    elif transfer_model == 'Xception':\n",
    "        with tf.device('/gpu:1'):\n",
    "            model_ = Xception(input_tensor = input_, weights = 'imagenet', include_top = False)\n",
    "        return Model(inputs = model_.input, outputs = model_.output)\n",
    "    elif transfer_model == 'DenseNet121':\n",
    "        with tf.device('/gpu:1'):\n",
    "            model_ = DenseNet121(input_tensor = input_, weights = 'imagenet', include_top = False)\n",
    "        return Model(inputs = model_.input, outputs = model_.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extract(gen, model):\n",
    "    return model.predict_generator(gen, steps = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_features(file, feature):\n",
    "    print('Saving {}'.format(file))\n",
    "    scipy.io.savemat(file, {'x': feature[0], 'y': feature[1]}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features from source data for model InceptionV3\n",
      "Extracting features from target data for model InceptionV3\n",
      "Saving /data/aumkar/data_load/InceptionV3.mat\n",
      "Saving /data/aumkar/data_load/InceptionV3_target.mat\n",
      "Extracting features from source data for model VGG16\n",
      "Extracting features from target data for model VGG16\n",
      "Saving /data/aumkar/data_load/VGG16.mat\n",
      "Saving /data/aumkar/data_load/VGG16_target.mat\n",
      "Extracting features from source data for model VGG19\n",
      "Extracting features from target data for model VGG19\n",
      "Saving /data/aumkar/data_load/VGG19.mat\n",
      "Saving /data/aumkar/data_load/VGG19_target.mat\n",
      "Extracting features from source data for model Xception\n",
      "Extracting features from target data for model Xception\n",
      "Saving /data/aumkar/data_load/Xception.mat\n",
      "Saving /data/aumkar/data_load/Xception_target.mat\n",
      "Extracting features from source data for model DenseNet121\n",
      "Extracting features from target data for model DenseNet121\n",
      "Saving /data/aumkar/data_load/DenseNet121.mat\n",
      "Saving /data/aumkar/data_load/DenseNet121_target.mat\n"
     ]
    }
   ],
   "source": [
    "for model in ['InceptionV3', 'VGG16', 'VGG19', 'Xception', 'DenseNet121']:\n",
    "    \n",
    "    filename = '{}/{}.mat'.format(DATA_LOAD_DIR, model)\n",
    "    filename_target = '{}/{}_target.mat'.format(DATA_LOAD_DIR, model)\n",
    "    transfer_model = model_create(model)\n",
    "    print('Extracting features from source data for model {}'.format(model))\n",
    "    features = feature_extract(source_generator, transfer_model)\n",
    "    print('Extracting features from target data for model {}'.format(model))\n",
    "    features_target = feature_extract(target_generator, transfer_model)\n",
    "    \n",
    "    for feature in [(features, y_source)]:\n",
    "        save_features(filename, feature)\n",
    "        \n",
    "    for feature in [(features_target, y_target)]:\n",
    "        save_features(filename_target, feature)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (daenv)",
   "language": "python",
   "name": "daenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
