{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import glob\n",
    "import random\n",
    "import scipy.ndimage\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from imutils import paths\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.applications import imagenet_utils\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = os.path.normpath(os.path.join(os.path.dirname(os.path.realpath('__file__'))))\n",
    "SOURCE_DIR = os.path.abspath('/data/aumkar/train')\n",
    "TARGET_DIR = os.path.abspath('/data/aumkar/validation')\n",
    "DATA_LOAD_DIR = os.path.abspath('/data/aumkar/data_load')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_path = list(paths.list_images(SOURCE_DIR))\n",
    "target_path = list(paths.list_images(TARGET_DIR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(source_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(target_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_source = [p.split(os.path.sep)[-2] for p in source_path]\n",
    "labels_target = [p.split(os.path.sep)[-2] for p in target_path]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "labels = le.fit_transform(labels_source)\n",
    "labels_t = le.fit_transform(labels_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_unique = np.unique(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join(DATA_LOAD_DIR, 'labels.npy'), labels_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_create(transfer_model):\n",
    "    if transfer_model == 'InceptionV3':\n",
    "        with tf.device('/gpu:1'):\n",
    "            return InceptionV3(weights = 'imagenet', include_top = False)\n",
    "    elif transfer_model == 'VGG16':\n",
    "        with tf.device('/gpu:1'):\n",
    "            return VGG16(weights = 'imagenet', include_top = False)\n",
    "    elif transfer_model == 'VGG19':\n",
    "        with tf.device('/gpu:1'):\n",
    "            return VGG19(weights = 'imagenet', include_top = False)\n",
    "    elif transfer_model == 'Xception':\n",
    "        with tf.device('/gpu:1'):\n",
    "            return Xception(weights = 'imagenet', include_top = False)\n",
    "    elif transfer_model == 'DenseNet121':\n",
    "        with tf.device('/gpu:1'):\n",
    "            return DenseNet121(weights = 'imagenet', include_top = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_reshape(transfer_model, features):\n",
    "    if transfer_model == 'InceptionV3':\n",
    "        return features.reshape((features.shape[0], 5 * 5 * 2048))\n",
    "    elif transfer_model == 'VGG16':\n",
    "        return features.reshape((features.shape[0], 7 * 7 * 512))\n",
    "    elif transfer_model == 'VGG19':\n",
    "        return features.reshape((features.shape[0], 7 * 7 * 512))\n",
    "    elif transfer_model == 'Xception':\n",
    "        return features.reshape((features.shape[0], 7 * 7 * 2048))\n",
    "    elif transfer_model == 'DenseNet121':\n",
    "        return features.reshape((features.shape[0], 7 * 7 * 1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_save(transfer_model, features, label, b, source):\n",
    "    if transfer_model == 'InceptionV3' and source == 'source':\n",
    "        np.savez_compressed(os.path.join(DATA_LOAD_DIR, 'inception', 'feat_incept_%s.npz' % b), a = features)\n",
    "        np.savez_compressed(os.path.join(DATA_LOAD_DIR, 'inception', 'feat_incept_label_%s.npz' % b), a = label)\n",
    "    elif transfer_model == 'InceptionV3' and source == 'target':\n",
    "        np.savez_compressed(os.path.join(DATA_LOAD_DIR, 'inception', 'feat_incept_target_%s.npz' % b), a = features)\n",
    "        np.savez_compressed(os.path.join(DATA_LOAD_DIR, 'inception', 'feat_incept_label_target_%s.npz' % b), a = label)\n",
    "    elif transfer_model == 'VGG16' and source == 'source':\n",
    "        np.savez_compressed(os.path.join(DATA_LOAD_DIR, 'vgg16', 'feat_vgg16_%s.npz' % b), a = features)\n",
    "        np.savez_compressed(os.path.join(DATA_LOAD_DIR, 'vgg16', 'feat_vgg16_label_%s.npz' % b), a = label)\n",
    "    elif transfer_model == 'VGG16' and source == 'target':\n",
    "        np.savez_compressed(os.path.join(DATA_LOAD_DIR, 'vgg16', 'feat_vgg16_target_%s.npz' % b), a = features)\n",
    "        np.savez_compressed(os.path.join(DATA_LOAD_DIR, 'vgg16', 'feat_vgg16_label_target_%s.npz' % b), a = label)\n",
    "    elif transfer_model == 'VGG19' and source == 'source':\n",
    "        np.savez_compressed(os.path.join(DATA_LOAD_DIR, 'vgg19', 'feat_vgg19_%s.npz' % b), a = features)\n",
    "        np.savez_compressed(os.path.join(DATA_LOAD_DIR, 'vgg19', 'feat_vgg19_label_%s.npz' % b), a = label)\n",
    "    elif transfer_model == 'VGG19' and source == 'target':\n",
    "        np.savez_compressed(os.path.join(DATA_LOAD_DIR, 'vgg19', 'feat_vgg19_target_%s.npz' % b), a = features)\n",
    "        np.savez_compressed(os.path.join(DATA_LOAD_DIR, 'vgg19', 'feat_vgg19_label_target_%s.npz' % b), a = label)\n",
    "    elif transfer_model == 'Xception' and source == 'source':\n",
    "        np.savez_compressed(os.path.join(DATA_LOAD_DIR, 'xception', 'feat_xcept_%s.npz' % b), a = features)\n",
    "        np.savez_compressed(os.path.join(DATA_LOAD_DIR, 'xception', 'feat_xcept_label_%s.npz' % b), a = label)\n",
    "    elif transfer_model == 'Xception' and source == 'target':\n",
    "        np.savez_compressed(os.path.join(DATA_LOAD_DIR, 'xception', 'feat_xcept_target_%s.npz' % b), a = features)\n",
    "        np.savez_compressed(os.path.join(DATA_LOAD_DIR, 'xception', 'feat_xcept_label_target_%s.npz' % b), a = label)\n",
    "    elif transfer_model == 'DenseNet121' and source == 'source':\n",
    "        np.savez_compressed(os.path.join(DATA_LOAD_DIR, 'densenet', 'feat_dense_%s.npz' % b), a = features)\n",
    "        np.savez_compressed(os.path.join(DATA_LOAD_DIR, 'densenet', 'feat_dense_label_%s.npz' % b), a = label)\n",
    "    elif transfer_model == 'DenseNet121' and source == 'target':\n",
    "        np.savez_compressed(os.path.join(DATA_LOAD_DIR, 'densenet', 'feat_dense_target_%s.npz' % b), a = features)\n",
    "        np.savez_compressed(os.path.join(DATA_LOAD_DIR, 'densenet', 'feat_dense_label_target_%s.npz' % b), a = label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extract(path, batch_size, labels, model_, source):\n",
    "    \n",
    "    model1 = model_create(model_)\n",
    "    \n",
    "    for (b, i) in enumerate(range(0, len(path), batch_size)):\n",
    "        # extract the batch of images and labels, then initialize the\n",
    "        # list of actual images that will be passed through the network\n",
    "        # for feature extraction\n",
    "        print(\"[INFO] processing batch {}/{}\".format(b + 1, int(np.ceil(len(path) / float(batch_size)))))\n",
    "        batchPaths = path[i: i + batch_size]\n",
    "        batchLabels = labels[i: i + batch_size]\n",
    "        batchImages = []\n",
    "\n",
    "        # loop over the images and labels in the current batch\n",
    "        for imagePath in batchPaths:\n",
    "            # load the input image using the Keras helper utility while\n",
    "            # ensuring the image is resized to 224x224 pixels\n",
    "            image = load_img(imagePath, target_size=(224, 224))\n",
    "            image = img_to_array(image)\n",
    "\n",
    "            # preprocess the image by (1) expanding the dimensions and\n",
    "            # (2) subtracting the mean RGB pixel intensity from the\n",
    "            # ImageNet dataset\n",
    "            image = np.expand_dims(image, axis=0)\n",
    "            image = imagenet_utils.preprocess_input(image)\n",
    "\n",
    "            # add the image to the batch\n",
    "            batchImages.append(image)\n",
    "\n",
    "        # pass the images through the network and use the outputs as our\n",
    "        # actual features, then reshape the features into a flattened\n",
    "        # volume\n",
    "        batchImages = np.vstack(batchImages)\n",
    "            \n",
    "        features = model1.predict(batchImages, batch_size = batch_size)\n",
    "        features1 = model_reshape(model_, features)\n",
    "\n",
    "        model_save(model_, features1, batchLabels, b, source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feature_extract(source_path, 64, labels, 'InceptionV3', 'source')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feature_extract(target_path, 64, labels_t, 'InceptionV3', 'target')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (daenv)",
   "language": "python",
   "name": "daenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
