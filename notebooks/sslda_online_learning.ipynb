{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import glob\n",
    "import random\n",
    "import scipy.ndimage\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from imutils import paths\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications import imagenet_utils\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = os.path.normpath(os.path.join(os.path.dirname(os.path.realpath('__file__'))))\n",
    "SOURCE_DIR = os.path.abspath('/data/aumkar/train')\n",
    "TARGET_DIR = os.path.abspath('/data/aumkar/validation')\n",
    "DATA_LOAD_DIR = os.path.abspath('/data/aumkar/data_load')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_path = list(paths.list_images(SOURCE_DIR))\n",
    "target_path = list(paths.list_images(TARGET_DIR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(source_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(target_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(152397, 55388)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(len(source_path), len(target_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_source = [p.split(os.path.sep)[-2] for p in source_path]\n",
    "labels_target = [p.split(os.path.sep)[-2] for p in target_path]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "labels = le.fit_transform(labels_source)\n",
    "labels_t = le.fit_transform(labels_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55388,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_unique = np.load(os.path.join(DATA_LOAD_DIR, 'labels.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {0 : 0.51, 1 : 1., 2 : 0.44, 3 : 0.57, 4 : 0.77, 5 : 0.51, 6 : 0.42, 7 : 0.6, 8 : 0.68, 9 : 0.63, 10 : 0.46, 11 : 0.76}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = linear_model.SGDClassifier(max_iter = 1000, tol = 1e-3, n_jobs = -1, class_weight = weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_create(transfer_model):\n",
    "    if transfer_model == 'InceptionV3':\n",
    "        with tf.device('/gpu:1'):\n",
    "            return InceptionV3(weights = 'imagenet', include_top = False)\n",
    "    elif transfer_model == 'VGG16':\n",
    "        with tf.device('/gpu:1'):\n",
    "            return VGG16(weights = 'imagenet', include_top = False)\n",
    "    elif transfer_model == 'VGG19':\n",
    "        with tf.device('/gpu:1'):\n",
    "            return VGG19(weights = 'imagenet', include_top = False)\n",
    "    elif transfer_model == 'Xception':\n",
    "        with tf.device('/gpu:1'):\n",
    "            return Xception(weights = 'imagenet', include_top = False)\n",
    "    elif transfer_model == 'DenseNet121':\n",
    "        with tf.device('/gpu:1'):\n",
    "            return DenseNet121(weights = 'imagenet', include_top = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_reshape(transfer_model, features):\n",
    "    if transfer_model == 'InceptionV3':\n",
    "        return features.reshape((features.shape[0], 5 * 5 * 2048))\n",
    "    elif transfer_model == 'VGG16':\n",
    "        return features.reshape((features.shape[0], 7 * 7 * 512))\n",
    "    elif transfer_model == 'VGG19':\n",
    "        return features.reshape((features.shape[0], 7 * 7 * 512))\n",
    "    elif transfer_model == 'Xception':\n",
    "        return features.reshape((features.shape[0], 7 * 7 * 2048))\n",
    "    elif transfer_model == 'DenseNet121':\n",
    "        return features.reshape((features.shape[0], 7 * 7 * 1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_train(i, model, features, label):\n",
    "    \n",
    "    print('Training batch: ', i + 1)\n",
    "    if i == 0:\n",
    "        model.partial_fit(features, label, classes = labels_unique)\n",
    "    else:\n",
    "        model.partial_fit(features, label)\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extract(tpath, spath, batch_size, pseudo_labels, source_labels, model_, source, trained_model, iteration, n_k):\n",
    "    \n",
    "    pred = []\n",
    "    model1 = model_create(model_)\n",
    "    \n",
    "    if source == 'target' and iteration != 0:\n",
    "        \n",
    "        idx = np.arange(len(tpath))\n",
    "        np.random.shuffle(idx)\n",
    "        \n",
    "        sampled_idxs = idx[:int(n_k)]\n",
    "        \n",
    "        target_sample = np.array(tpath)[sampled_idxs]\n",
    "        labels_sample = pseudo_labels[sampled_idxs]\n",
    "        \n",
    "        spath.extend(target_sample.tolist())\n",
    "        source_labels.tolist().extend(labels_sample)\n",
    "        \n",
    "    for (b, i) in enumerate(range(0, len(spath), batch_size)):\n",
    "        # extract the batch of images and labels, then initialize the\n",
    "        # list of actual images that will be passed through the network\n",
    "        # for feature extraction\n",
    "        print(\"Processing batch {}/{}\".format(b + 1, int(np.ceil(len(spath) / float(batch_size)))))\n",
    "        batchPaths = spath[i: i + batch_size]\n",
    "        batchLabels = np.array(source_labels)[i: i + batch_size]\n",
    "        batchImages = []\n",
    "\n",
    "        # loop over the images and labels in the current batch\n",
    "        for imagePath in batchPaths:\n",
    "            # load the input image using the Keras helper utility while\n",
    "            # ensuring the image is resized to 224x224 pixels\n",
    "            image = load_img(imagePath, target_size=(224, 224))\n",
    "            image = img_to_array(image)\n",
    "\n",
    "            # preprocess the image by (1) expanding the dimensions and\n",
    "            # (2) subtracting the mean RGB pixel intensity from the\n",
    "            # ImageNet dataset\n",
    "            image = np.expand_dims(image, axis=0)\n",
    "            image = imagenet_utils.preprocess_input(image)\n",
    "\n",
    "            # add the image to the batch\n",
    "            batchImages.append(image)\n",
    "\n",
    "        # pass the images through the network and use the outputs as our\n",
    "        # actual features, then reshape the features into a flattened\n",
    "        # volume\n",
    "        batchImages = np.vstack(batchImages)\n",
    "            \n",
    "        features = model1.predict(batchImages, batch_size = batch_size)\n",
    "        features1 = model_reshape(model_, features)\n",
    "        \n",
    "        if source == 'source' and b == 0 and iteration == 0:\n",
    "            model_partial = model_train(b, clf, features1, batchLabels)\n",
    "        elif source == 'source' and b != 0 and iteration == 0:\n",
    "            model_partial = model_train(b, model_partial, features1, batchLabels)\n",
    "        elif source == 'target' and iteration == 0:\n",
    "            pred.append(target_pred(trained_model, features1))\n",
    "        elif source == 'target' and b == 0 and iteration != 0:\n",
    "            model_partial = model_train(b, clf, features1, batchLabels)\n",
    "        elif source == 'target' and b != 0 and iteration != 0:\n",
    "            model_partial = model_train(b, model_partial, features1, batchLabels)\n",
    "            \n",
    "    if source == 'target' and iteration != 0:\n",
    "        return fin_model\n",
    "    if source == 'source' and iteration == 0:\n",
    "        return model_partial\n",
    "    elif source == 'target' and iteration == 0:\n",
    "        return np.hstack(np.asarray(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_pred(model, target_features):\n",
    "    \n",
    "    print('Predicting batch features')\n",
    "    return model.predict(target_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sslda_online(M):\n",
    "    \n",
    "    score = []\n",
    "    \n",
    "    svm_model = feature_extract(None, source_path, 256, None, labels, 'InceptionV3', 'source', None, 0, None)\n",
    "    \n",
    "    target_predictions = feature_extract(None, target_path, 256, None, labels_t, 'InceptionV3', 'target', svm_model, 0, None)\n",
    "    \n",
    "    for i in range(1, M):\n",
    "        \n",
    "        print('Iteration: ', i)\n",
    "         \n",
    "        n = (i / float(M)) * len(target_path)\n",
    "        \n",
    "        if i == 1:\n",
    "            mod = feature_extract(target_path, source_path, 256, target_predictions, labels, 'InceptionV3', 'target', None, i, n)\n",
    "            fin_pred = feature_extract(None, target_path, 256, None, labels_t, 'InceptionV3', 'target', mod, 0, None)\n",
    "        else:\n",
    "            mod = feature_extract(target_path, source_path, 256, fin_pred, labels, 'InceptionV3', 'target', None, i, n)\n",
    "            fin_pred = feature_extract(None, target_path, 256, None, labels_t, 'InceptionV3', 'target', mod, 0, None)\n",
    "        \n",
    "        score.append(accuracy_score(labels_t, fin_pred))\n",
    "        \n",
    "    return fin_pred, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('ENSEMBLE ITERATION: ', 1)\n",
      "Processing batch 1/596\n",
      "('Training batch: ', 1)\n",
      "Processing batch 2/596\n",
      "('Training batch: ', 2)\n",
      "Processing batch 3/596\n",
      "('Training batch: ', 3)\n",
      "Processing batch 4/596\n",
      "('Training batch: ', 4)\n",
      "Processing batch 5/596\n",
      "('Training batch: ', 5)\n",
      "Processing batch 6/596\n",
      "('Training batch: ', 6)\n",
      "Processing batch 7/596\n",
      "('Training batch: ', 7)\n",
      "Processing batch 8/596\n",
      "('Training batch: ', 8)\n",
      "Processing batch 9/596\n",
      "('Training batch: ', 9)\n",
      "Processing batch 10/596\n",
      "('Training batch: ', 10)\n",
      "Processing batch 11/596\n",
      "('Training batch: ', 11)\n",
      "Processing batch 12/596\n",
      "('Training batch: ', 12)\n",
      "Processing batch 13/596\n",
      "('Training batch: ', 13)\n",
      "Processing batch 14/596\n",
      "('Training batch: ', 14)\n",
      "Processing batch 15/596\n",
      "('Training batch: ', 15)\n",
      "Processing batch 16/596\n",
      "('Training batch: ', 16)\n",
      "Processing batch 17/596\n",
      "('Training batch: ', 17)\n",
      "Processing batch 18/596\n",
      "('Training batch: ', 18)\n",
      "Processing batch 19/596\n",
      "('Training batch: ', 19)\n",
      "Processing batch 20/596\n",
      "('Training batch: ', 20)\n",
      "Processing batch 21/596\n",
      "('Training batch: ', 21)\n",
      "Processing batch 22/596\n",
      "('Training batch: ', 22)\n",
      "Processing batch 23/596\n",
      "('Training batch: ', 23)\n",
      "Processing batch 24/596\n",
      "('Training batch: ', 24)\n",
      "Processing batch 25/596\n",
      "('Training batch: ', 25)\n",
      "Processing batch 26/596\n",
      "('Training batch: ', 26)\n",
      "Processing batch 27/596\n",
      "('Training batch: ', 27)\n",
      "Processing batch 28/596\n",
      "('Training batch: ', 28)\n",
      "Processing batch 29/596\n",
      "('Training batch: ', 29)\n",
      "Processing batch 30/596\n",
      "('Training batch: ', 30)\n",
      "Processing batch 31/596\n",
      "('Training batch: ', 31)\n",
      "Processing batch 32/596\n",
      "('Training batch: ', 32)\n",
      "Processing batch 33/596\n",
      "('Training batch: ', 33)\n",
      "Processing batch 34/596\n",
      "('Training batch: ', 34)\n",
      "Processing batch 35/596\n",
      "('Training batch: ', 35)\n",
      "Processing batch 36/596\n",
      "('Training batch: ', 36)\n",
      "Processing batch 37/596\n",
      "('Training batch: ', 37)\n",
      "Processing batch 38/596\n",
      "('Training batch: ', 38)\n",
      "Processing batch 39/596\n",
      "('Training batch: ', 39)\n",
      "Processing batch 40/596\n",
      "('Training batch: ', 40)\n",
      "Processing batch 41/596\n",
      "('Training batch: ', 41)\n",
      "Processing batch 42/596\n",
      "('Training batch: ', 42)\n",
      "Processing batch 43/596\n",
      "('Training batch: ', 43)\n",
      "Processing batch 44/596\n",
      "('Training batch: ', 44)\n",
      "Processing batch 45/596\n",
      "('Training batch: ', 45)\n",
      "Processing batch 46/596\n",
      "('Training batch: ', 46)\n",
      "Processing batch 47/596\n",
      "('Training batch: ', 47)\n",
      "Processing batch 48/596\n",
      "('Training batch: ', 48)\n",
      "Processing batch 49/596\n",
      "('Training batch: ', 49)\n",
      "Processing batch 50/596\n",
      "('Training batch: ', 50)\n",
      "Processing batch 51/596\n",
      "('Training batch: ', 51)\n",
      "Processing batch 52/596\n",
      "('Training batch: ', 52)\n",
      "Processing batch 53/596\n",
      "('Training batch: ', 53)\n",
      "Processing batch 54/596\n",
      "('Training batch: ', 54)\n",
      "Processing batch 55/596\n",
      "('Training batch: ', 55)\n",
      "Processing batch 56/596\n",
      "('Training batch: ', 56)\n",
      "Processing batch 57/596\n",
      "('Training batch: ', 57)\n",
      "Processing batch 58/596\n",
      "('Training batch: ', 58)\n",
      "Processing batch 59/596\n",
      "('Training batch: ', 59)\n",
      "Processing batch 60/596\n",
      "('Training batch: ', 60)\n",
      "Processing batch 61/596\n",
      "('Training batch: ', 61)\n",
      "Processing batch 62/596\n",
      "('Training batch: ', 62)\n",
      "Processing batch 63/596\n",
      "('Training batch: ', 63)\n",
      "Processing batch 64/596\n",
      "('Training batch: ', 64)\n",
      "Processing batch 65/596\n",
      "('Training batch: ', 65)\n",
      "Processing batch 66/596\n",
      "('Training batch: ', 66)\n",
      "Processing batch 67/596\n",
      "('Training batch: ', 67)\n",
      "Processing batch 68/596\n",
      "('Training batch: ', 68)\n",
      "Processing batch 69/596\n",
      "('Training batch: ', 69)\n",
      "Processing batch 70/596\n",
      "('Training batch: ', 70)\n",
      "Processing batch 71/596\n",
      "('Training batch: ', 71)\n",
      "Processing batch 72/596\n",
      "('Training batch: ', 72)\n",
      "Processing batch 73/596\n",
      "('Training batch: ', 73)\n",
      "Processing batch 74/596\n",
      "('Training batch: ', 74)\n",
      "Processing batch 75/596\n",
      "('Training batch: ', 75)\n",
      "Processing batch 76/596\n",
      "('Training batch: ', 76)\n",
      "Processing batch 77/596\n",
      "('Training batch: ', 77)\n",
      "Processing batch 78/596\n",
      "('Training batch: ', 78)\n",
      "Processing batch 79/596\n",
      "('Training batch: ', 79)\n",
      "Processing batch 80/596\n",
      "('Training batch: ', 80)\n",
      "Processing batch 81/596\n",
      "('Training batch: ', 81)\n",
      "Processing batch 82/596\n",
      "('Training batch: ', 82)\n",
      "Processing batch 83/596\n",
      "('Training batch: ', 83)\n",
      "Processing batch 84/596\n",
      "('Training batch: ', 84)\n",
      "Processing batch 85/596\n",
      "('Training batch: ', 85)\n",
      "Processing batch 86/596\n",
      "('Training batch: ', 86)\n",
      "Processing batch 87/596\n",
      "('Training batch: ', 87)\n",
      "Processing batch 88/596\n",
      "('Training batch: ', 88)\n",
      "Processing batch 89/596\n",
      "('Training batch: ', 89)\n",
      "Processing batch 90/596\n",
      "('Training batch: ', 90)\n",
      "Processing batch 91/596\n",
      "('Training batch: ', 91)\n",
      "Processing batch 92/596\n",
      "('Training batch: ', 92)\n",
      "Processing batch 93/596\n",
      "('Training batch: ', 93)\n",
      "Processing batch 94/596\n",
      "('Training batch: ', 94)\n",
      "Processing batch 95/596\n",
      "('Training batch: ', 95)\n",
      "Processing batch 96/596\n",
      "('Training batch: ', 96)\n",
      "Processing batch 97/596\n",
      "('Training batch: ', 97)\n",
      "Processing batch 98/596\n",
      "('Training batch: ', 98)\n",
      "Processing batch 99/596\n",
      "('Training batch: ', 99)\n",
      "Processing batch 100/596\n",
      "('Training batch: ', 100)\n",
      "Processing batch 101/596\n",
      "('Training batch: ', 101)\n",
      "Processing batch 102/596\n",
      "('Training batch: ', 102)\n",
      "Processing batch 103/596\n",
      "('Training batch: ', 103)\n",
      "Processing batch 104/596\n",
      "('Training batch: ', 104)\n",
      "Processing batch 105/596\n",
      "('Training batch: ', 105)\n",
      "Processing batch 106/596\n",
      "('Training batch: ', 106)\n",
      "Processing batch 107/596\n",
      "('Training batch: ', 107)\n",
      "Processing batch 108/596\n",
      "('Training batch: ', 108)\n",
      "Processing batch 109/596\n",
      "('Training batch: ', 109)\n",
      "Processing batch 110/596\n",
      "('Training batch: ', 110)\n",
      "Processing batch 111/596\n",
      "('Training batch: ', 111)\n",
      "Processing batch 112/596\n",
      "('Training batch: ', 112)\n",
      "Processing batch 113/596\n",
      "('Training batch: ', 113)\n",
      "Processing batch 114/596\n",
      "('Training batch: ', 114)\n",
      "Processing batch 115/596\n",
      "('Training batch: ', 115)\n",
      "Processing batch 116/596\n",
      "('Training batch: ', 116)\n",
      "Processing batch 117/596\n",
      "('Training batch: ', 117)\n",
      "Processing batch 118/596\n",
      "('Training batch: ', 118)\n",
      "Processing batch 119/596\n",
      "('Training batch: ', 119)\n",
      "Processing batch 120/596\n",
      "('Training batch: ', 120)\n",
      "Processing batch 121/596\n",
      "('Training batch: ', 121)\n",
      "Processing batch 122/596\n",
      "('Training batch: ', 122)\n",
      "Processing batch 123/596\n",
      "('Training batch: ', 123)\n",
      "Processing batch 124/596\n",
      "('Training batch: ', 124)\n",
      "Processing batch 125/596\n",
      "('Training batch: ', 125)\n",
      "Processing batch 126/596\n",
      "('Training batch: ', 126)\n",
      "Processing batch 127/596\n",
      "('Training batch: ', 127)\n",
      "Processing batch 128/596\n",
      "('Training batch: ', 128)\n",
      "Processing batch 129/596\n",
      "('Training batch: ', 129)\n",
      "Processing batch 130/596\n",
      "('Training batch: ', 130)\n",
      "Processing batch 131/596\n",
      "('Training batch: ', 131)\n",
      "Processing batch 132/596\n",
      "('Training batch: ', 132)\n",
      "Processing batch 133/596\n",
      "('Training batch: ', 133)\n",
      "Processing batch 134/596\n",
      "('Training batch: ', 134)\n",
      "Processing batch 135/596\n",
      "('Training batch: ', 135)\n",
      "Processing batch 136/596\n",
      "('Training batch: ', 136)\n",
      "Processing batch 137/596\n",
      "('Training batch: ', 137)\n",
      "Processing batch 138/596\n",
      "('Training batch: ', 138)\n",
      "Processing batch 139/596\n",
      "('Training batch: ', 139)\n",
      "Processing batch 140/596\n",
      "('Training batch: ', 140)\n",
      "Processing batch 141/596\n",
      "('Training batch: ', 141)\n",
      "Processing batch 142/596\n",
      "('Training batch: ', 142)\n",
      "Processing batch 143/596\n",
      "('Training batch: ', 143)\n",
      "Processing batch 144/596\n",
      "('Training batch: ', 144)\n",
      "Processing batch 145/596\n",
      "('Training batch: ', 145)\n",
      "Processing batch 146/596\n",
      "('Training batch: ', 146)\n",
      "Processing batch 147/596\n",
      "('Training batch: ', 147)\n",
      "Processing batch 148/596\n",
      "('Training batch: ', 148)\n",
      "Processing batch 149/596\n",
      "('Training batch: ', 149)\n",
      "Processing batch 150/596\n",
      "('Training batch: ', 150)\n",
      "Processing batch 151/596\n",
      "('Training batch: ', 151)\n",
      "Processing batch 152/596\n",
      "('Training batch: ', 152)\n",
      "Processing batch 153/596\n",
      "('Training batch: ', 153)\n",
      "Processing batch 154/596\n",
      "('Training batch: ', 154)\n",
      "Processing batch 155/596\n",
      "('Training batch: ', 155)\n",
      "Processing batch 156/596\n",
      "('Training batch: ', 156)\n",
      "Processing batch 157/596\n",
      "('Training batch: ', 157)\n",
      "Processing batch 158/596\n",
      "('Training batch: ', 158)\n",
      "Processing batch 159/596\n",
      "('Training batch: ', 159)\n",
      "Processing batch 160/596\n",
      "('Training batch: ', 160)\n",
      "Processing batch 161/596\n",
      "('Training batch: ', 161)\n",
      "Processing batch 162/596\n",
      "('Training batch: ', 162)\n",
      "Processing batch 163/596\n",
      "('Training batch: ', 163)\n",
      "Processing batch 164/596\n",
      "('Training batch: ', 164)\n",
      "Processing batch 165/596\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Training batch: ', 165)\n",
      "Processing batch 166/596\n",
      "('Training batch: ', 166)\n",
      "Processing batch 167/596\n",
      "('Training batch: ', 167)\n",
      "Processing batch 168/596\n",
      "('Training batch: ', 168)\n",
      "Processing batch 169/596\n",
      "('Training batch: ', 169)\n",
      "Processing batch 170/596\n",
      "('Training batch: ', 170)\n",
      "Processing batch 171/596\n",
      "('Training batch: ', 171)\n",
      "Processing batch 172/596\n",
      "('Training batch: ', 172)\n",
      "Processing batch 173/596\n",
      "('Training batch: ', 173)\n",
      "Processing batch 174/596\n",
      "('Training batch: ', 174)\n",
      "Processing batch 175/596\n",
      "('Training batch: ', 175)\n",
      "Processing batch 176/596\n",
      "('Training batch: ', 176)\n",
      "Processing batch 177/596\n",
      "('Training batch: ', 177)\n",
      "Processing batch 178/596\n",
      "('Training batch: ', 178)\n",
      "Processing batch 179/596\n",
      "('Training batch: ', 179)\n",
      "Processing batch 180/596\n",
      "('Training batch: ', 180)\n",
      "Processing batch 181/596\n",
      "('Training batch: ', 181)\n",
      "Processing batch 182/596\n",
      "('Training batch: ', 182)\n",
      "Processing batch 183/596\n",
      "('Training batch: ', 183)\n",
      "Processing batch 184/596\n",
      "('Training batch: ', 184)\n",
      "Processing batch 185/596\n",
      "('Training batch: ', 185)\n",
      "Processing batch 186/596\n",
      "('Training batch: ', 186)\n",
      "Processing batch 187/596\n",
      "('Training batch: ', 187)\n",
      "Processing batch 188/596\n",
      "('Training batch: ', 188)\n",
      "Processing batch 189/596\n",
      "('Training batch: ', 189)\n",
      "Processing batch 190/596\n",
      "('Training batch: ', 190)\n",
      "Processing batch 191/596\n",
      "('Training batch: ', 191)\n",
      "Processing batch 192/596\n",
      "('Training batch: ', 192)\n",
      "Processing batch 193/596\n",
      "('Training batch: ', 193)\n",
      "Processing batch 194/596\n",
      "('Training batch: ', 194)\n",
      "Processing batch 195/596\n",
      "('Training batch: ', 195)\n",
      "Processing batch 196/596\n",
      "('Training batch: ', 196)\n",
      "Processing batch 197/596\n",
      "('Training batch: ', 197)\n",
      "Processing batch 198/596\n",
      "('Training batch: ', 198)\n",
      "Processing batch 199/596\n",
      "('Training batch: ', 199)\n",
      "Processing batch 200/596\n",
      "('Training batch: ', 200)\n",
      "Processing batch 201/596\n",
      "('Training batch: ', 201)\n",
      "Processing batch 202/596\n",
      "('Training batch: ', 202)\n",
      "Processing batch 203/596\n",
      "('Training batch: ', 203)\n",
      "Processing batch 204/596\n",
      "('Training batch: ', 204)\n",
      "Processing batch 205/596\n",
      "('Training batch: ', 205)\n",
      "Processing batch 206/596\n",
      "('Training batch: ', 206)\n",
      "Processing batch 207/596\n",
      "('Training batch: ', 207)\n",
      "Processing batch 208/596\n",
      "('Training batch: ', 208)\n",
      "Processing batch 209/596\n",
      "('Training batch: ', 209)\n",
      "Processing batch 210/596\n",
      "('Training batch: ', 210)\n",
      "Processing batch 211/596\n",
      "('Training batch: ', 211)\n",
      "Processing batch 212/596\n",
      "('Training batch: ', 212)\n",
      "Processing batch 213/596\n",
      "('Training batch: ', 213)\n",
      "Processing batch 214/596\n",
      "('Training batch: ', 214)\n",
      "Processing batch 215/596\n"
     ]
    }
   ],
   "source": [
    "pred = []\n",
    "mean_acc = []\n",
    "\n",
    "for i in range(3):\n",
    "    \n",
    "    print('ENSEMBLE ITERATION: ', i+1)\n",
    "    \n",
    "    sslda_pred, acc = sslda_online(10)\n",
    "    \n",
    "    pred.append(sslda_pred)\n",
    "    mean_acc.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in mean_acc:\n",
    "    plt.figure()\n",
    "    plt.plot(i)\n",
    "    plt.title('Accuracy over iterations (for model %s)' % i)\n",
    "    plt.xlabel('# Iterations')\n",
    "    plt.ylabel('SVM mean accuracy')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['aeroplane', 'bicycle', 'bus', 'car', 'horse', 'knife', 'motorcycle', 'person', 'plant', 'skateboard', \n",
    "           'train', 'truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in pred:\n",
    "    print(classification_report(labels_t, i, target_names = classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "majority_vote = np.maximum.reduce([pred[0], pred[1], pred[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(labels_t, majority_vote, target_names = classes))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (daenv)",
   "language": "python",
   "name": "daenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
