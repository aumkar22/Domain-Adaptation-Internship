{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import csv\n",
    "import os\n",
    "import itertools\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.layers import *\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.mobilenet import MobileNet\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.applications.xception import Xception\n",
    "from keras.applications.densenet import DenseNet121\n",
    "from keras import backend as k\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = os.path.normpath(os.path.join(os.path.dirname(os.path.realpath('__file__'))))\n",
    "TRAIN_DIR = os.path.join(ROOT_DIR, 'data', 'train')\n",
    "TEST_DIR =  os.path.join(ROOT_DIR, 'data', 'validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width, img_height = 300, 300\n",
    "x_train, x_test, trainy, testy = [], [], [], []\n",
    "batch_ = 0\n",
    "batch_test = 0\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = ImageDataGenerator(rescale=1. / 255, zoom_range=0.2, horizontal_flip = True, vertical_flip = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 152397 images belonging to 13 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_gen.flow_from_directory(TRAIN_DIR, target_size=(img_width, img_height), \n",
    "                                                batch_size=batch_size, class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gen = ImageDataGenerator(rescale=1. / 255, zoom_range=0.2, horizontal_flip = True, vertical_flip = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 55388 images belonging to 13 classes.\n"
     ]
    }
   ],
   "source": [
    "test_generator = test_gen.flow_from_directory(TEST_DIR, target_size=(img_width, img_height), \n",
    "                                                batch_size=batch_size, class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_generator.classes\n",
    "y_test = test_generator.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = Input(shape=(img_width, img_height, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_create(transfer_model):\n",
    "    if transfer_model == 'InceptionV3':\n",
    "        with tf.device('/gpu:1'):\n",
    "            model_ = InceptionV3(input_tensor = input_, weights = 'imagenet', include_top = False)\n",
    "        return Model(inputs = model_.input, outputs = model_.output)\n",
    "    elif transfer_model == 'MobileNet':\n",
    "        with tf.device('/gpu:1'):\n",
    "            model_ = MobileNet(input_tensor = input_, weights = 'imagenet', include_top = False)\n",
    "        return Model(inputs = model_.input, outputs = model_.output)\n",
    "    elif transfer_model == 'VGG16':\n",
    "        with tf.device('/gpu:1'):\n",
    "            model_ = VGG16(input_tensor = input_, weights = 'imagenet', include_top = False)\n",
    "        return Model(inputs = model_.input, outputs = model_.output)\n",
    "    elif transfer_model == 'VGG19':\n",
    "        with tf.device('/gpu:1'):\n",
    "            model_ = VGG19(input_tensor = input_, weights = 'imagenet', include_top = False)\n",
    "        return Model(inputs = model_.input, outputs = model_.output)\n",
    "    elif transfer_model == 'Xception':\n",
    "        with tf.device('/gpu:1'):\n",
    "            model_ = Xception(input_tensor = input_, weights = 'imagenet', include_top = False)\n",
    "        return Model(inputs = model_.input, outputs = model_.output)\n",
    "    elif transfer_model == 'DenseNet121':\n",
    "        with tf.device('/gpu:1'):\n",
    "            model_ = DenseNet121(input_tensor = input_, weights = 'imagenet', include_top = False)\n",
    "        return Model(inputs = model_.input, outputs = model_.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extract(gen, model, y):\n",
    "    return model.predict_generator(gen, int(len(y)/batch_size + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_features(file, feature):\n",
    "    print('Saving {}'.format(file))\n",
    "    scipy.io.savemat(file, {'x': feature[0], 'y': feature[1]}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InceptionV3\n",
      "Extracting features from train data for model InceptionV3\n"
     ]
    }
   ],
   "source": [
    "for model in ['InceptionV3', 'MobileNet', 'VGG16', 'VGG19', 'Xception', 'DenseNet121']:\n",
    "    print(model)\n",
    "    filename = '{}/{}.mat'.format(ROOT_DIR, model)\n",
    "    transfer_model = model_create(model)\n",
    "    print('Extracting features from train data for model {}'.format(model))\n",
    "    features = feature_extract(train_generator, transfer_model, y_train)\n",
    "    print('Extracting features from test data for model {}'.format(model))\n",
    "    features_test = feature_extract(test_generator, transfer_model, y_test)\n",
    "    \n",
    "    for feature in [(features, y_train), (features_test, y_test)]:\n",
    "        save_features(filename, feature)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (daenv)",
   "language": "python",
   "name": "daenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
